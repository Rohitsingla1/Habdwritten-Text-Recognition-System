{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRIU_NDnGjqM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "# referenee to our executable file so we us this below\n",
        "pytesseract.pytesseract.tesseract_cmd='C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
        "# to read image\n",
        "img=cv2.imread('9.png')\n",
        "                # path\n",
        "# the thing with pytesseract is that it only accept RGB values while opencv\n",
        "# in BGR so first we will convert before sending\n",
        "# it to pytesseract library\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# it will convert the given image to string\n",
        "print(pytesseract.image_to_string(img))\n",
        "\n",
        "# it will give the details of each letters like\n",
        "# x axis y axis width and height which in actual diagonal points\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Detecting characters by characters\n",
        "# print(pytesseract.image_to_boxes(img))\n",
        "# hImg,wImg,_=img.shape\n",
        "# boxes =pytesseract.image_to_boxes(img)\n",
        "# for b in boxes.splitlines():\n",
        "#     # print(b) # we will be getting the same info as above\n",
        "#     b=b.split(' ')# convert all the elemnets to list\n",
        "#     print(b)\n",
        "#     x,y,w,h=int (b[1]),int (b[2]),int(b[3]),int(b[4])\n",
        "#     cv2.rectangle(img,(x,hImg-y),(w,hImg-h),(0,0,225),3)\n",
        "#     # if they were detected properly or not\n",
        "#     #  to detect word by word\n",
        "#     cv2.putText(img,b[0],(x,hImg-y+25),cv2.FONT_HERSHEY_COMPLEX,1,(50,50,255),1)\n",
        "#\n",
        "# # # after conversion we can display\n",
        "# cv2.imshow('Result',img)\n",
        "#\n",
        "# # # used to delay the image\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "\n",
        "\n",
        "# ## DETECTING  words\n",
        "# hImg,wImg,_=img.shape\n",
        "# boxes =pytesseract.image_to_data(img)\n",
        "# # print(boxes)\n",
        "# for x,b in enumerate(boxes.splitlines()):\n",
        "#     # print(b) # we will be getting the same info as above\n",
        "#     if x!=0:\n",
        "#         b=b.split()# convert all the elemnets to list\n",
        "#         #print(b)\n",
        "#         if len(b)==12:\n",
        "#             x,y,w,h=int (b[6]),int (b[7]),int(b[8]),int(b[9])\n",
        "#             cv2.rectangle(img,(x,y),(w+x,h+y),(0,0,225),3)\n",
        "#             # if they were detected properly or not\n",
        "#             #  to detect word by word\n",
        "#             cv2.putText(img,b[11],(x,y),cv2.FONT_HERSHEY_COMPLEX,1,(50,50,255),1)\n",
        "# # after conversion we can display\n",
        "# cv2.imshow('Result',img)\n",
        "#\n",
        "# # used to delay the image\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "\n",
        "### DETECTING  Digits\n",
        "hImg,wImg,_=img.shape\n",
        "cong=r'--oem 3 --psm 6 outputbase  digits'\n",
        "# --psm controls the automatic Page Segmentation Mode\n",
        "# here 6 is single uniform block of text by default\n",
        "boxes =pytesseract.image_to_data(img,config=cong)\n",
        "# print(boxes)\n",
        "for x,b in enumerate(boxes.splitlines()):\n",
        "    # print(b) # we will be getting the same info as above\n",
        "    if x!=0:\n",
        "        b=b.split()# convert all the elemnets to list\n",
        "        print(b)\n",
        "        if len(b)==12:\n",
        "            x,y,w,h=int (b[6]),int (b[7]),int(b[8]),int(b[9])\n",
        "            cv2.rectangle(img,(x,y),(w+x,h+y),(0,0,225),3)\n",
        "            # if they were detected properly or not\n",
        "            #  to detect word by word\n",
        "            cv2.putText(img,b[11],(x,y),cv2.FONT_HERSHEY_COMPLEX,1,(50,50,255),1)\n",
        "# after conversion we can display\n",
        "cv2.imshow('Result',img)\n",
        "\n",
        "# used to delay the image\n",
        "cv2.waitKey(0)"
      ]
    }
  ]
}